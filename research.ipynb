{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.Utils import TextCleaner\n",
    "from pdfminer.high_level import extract_text\n",
    "import spacy \n",
    "resume_paths = [r\"D:\\DS\\resumes\\acads\\link.pdf\"]\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    return extract_text(pdf_path)\n",
    "\n",
    "for resume_path in resume_paths:\n",
    "    text = extract_text_from_pdf(resume_path)\n",
    "\n",
    "text = text\n",
    "clean_text = TextCleaner.clean_text(text)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "doc = nlp(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_links(text):\n",
    "    link_pattern = r'\\b(?:https?://|www\\.)\\S+\\b'\n",
    "    links = re.findall(link_pattern, text)\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://github.com/passwordresetGenerativeAI']\n"
     ]
    }
   ],
   "source": [
    "links = extract_links(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESUME_SECTIONS = [\n",
    "    'Contact Information',\n",
    "    'Objective',\n",
    "    'Summary',\n",
    "    'Education',\n",
    "    'Experience',\n",
    "    'Skills',\n",
    "    'Projects',\n",
    "    'Certifications',\n",
    "    'Licenses',\n",
    "    'Awards',\n",
    "    'Honors',\n",
    "    'Publications',\n",
    "    'References',\n",
    "    'Technical Skills',\n",
    "    'Computer Skills',\n",
    "    'Programming Languages',\n",
    "    'Software Skills',\n",
    "    'Soft Skills',\n",
    "    'Language Skills',\n",
    "    'Professional Skills',\n",
    "    'Transferable Skills',\n",
    "    'Work Experience',\n",
    "    'Professional Experience',\n",
    "    'Employment History',\n",
    "    'Internship Experience',\n",
    "    'Volunteer Experience',\n",
    "    'Leadership Experience',\n",
    "    'Research Experience',\n",
    "    'Teaching Experience'\n",
    "]\n",
    "def extract_experience(doc):\n",
    "    \"\"\"\n",
    "    Extract experience from a given string. It does so by using the Spacy module.\n",
    "\n",
    "    Args:\n",
    "        text (str): The string from which to extract experience.\n",
    "\n",
    "    Returns:\n",
    "        str: A string containing all the extracted experience.\n",
    "    \"\"\"\n",
    "    experience_section = []\n",
    "    in_experience_section = False\n",
    "\n",
    "    for token in doc:\n",
    "        print(in_experience_section)\n",
    "        if token.text in RESUME_SECTIONS:\n",
    "            if token.text in ['Experience', 'EXPERIENCE', 'experience']:\n",
    "                in_experience_section = True\n",
    "            else:\n",
    "                in_experience_section = False\n",
    "\n",
    "        if in_experience_section:\n",
    "            print(token.text)\n",
    "            print(in_experience_section)\n",
    "            experience_section.append(token.text)\n",
    "\n",
    "    return ' '.join(experience_section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Abin Devassia\\n♂phone+919778575276 /envel⌢peabin.devassia.2024@anderson.ucla.edu /linkedinlinkedin /githubGitHub\\nEducation\\nUCLA ANDERSON SCHOOL OF MANAGEMENT Los Angeles, CA\\nMaster of Science in Business Analytics (MSBA) Expected December 2024\\n•UCLA Anderson Merit Fellowship\\n•LLM,\\nhttps://github.com/password resetGenerativeAI, NLP, MachineLearningforDecisionMaking, StatisticalAnalyticsusingR, OptimizationusingPython, OperationsAnalytics, CustomerAnalytics\\nIIT Kharagpur Kharagpur, India\\nOcean Engineering & Naval Architecture April 2019\\n•Merit Scholarship Recipient\\n•Gold Medal, Bhandarkar Cup, Institute Blue, Alumni Cup for Being Best All Rounder\\nTechnical Skills\\n•Languages and Softwares: Python, R, SQL ,Tableau, Power BI\\n•Analytics Skills: Machine Learning, Time Series Analysis, EDA, NLP, Optimization, Inferential Statistics\\nExperience\\nOncoSoft Jul 2023 – Present\\nDeep Learning Engineering Intern Remote, India\\n•Developed an algorithm for resume parsing using the NLP library spaCy.\\n•Utilizing strengths of LLM to generate resume scoring system, streamlining the process of resume shortlisting.\\nLetsTransport Jun 2022 – Sep 2023\\nBusiness Analyst Banglore, India\\n•Championed concept of round tripping & implemented intricate algorithms to enhance round-tripping process,\\nresulting in a 2% margin enhancement, 30% fuel efficiency improvement, and 20% labor productivity increase.\\n•Engineered automated pipelines using Python to extract data from heterogeneous portals, monitor Google Sheet\\nchanges, and track revenue. This resulted in a 90-hour reduction in labor hours per week.\\n•Harnessed power of Large Language Models (LLMs) to summarize unstructured user feedback, reducing weekly\\noperational hours by 40. Also engineered an API for fuzzy name matching using LLMs, enhancing data accuracy.\\n•Strategically re-engineered incumbent tables by introducing supplementary columns to facilitate seamless query\\noptimization, yielding a remarkable 60% reduction in query response time for certain cases.\\nCocogenes Feb 2021 – Feb 2022\\nData Scientist Wayanad, India\\n•Parsed data on medicinal & chemical properties, geographical distribution of medicinal plants using Spacy.\\n•Developed an end-to-end computer vision classification project that accurately identifies plant species based on\\ntheir leaves, achieving an impressive 92% Mean Squared Error (MSE) for classification.\\nClimate Connect Digital Nov 2020 – Jan 2021\\nData Science Intern Remote\\n•Conducted time-series forecasting of electricity demand for Delhi DISCOM, leveraging statistical analysis of\\nload and weather data. Utilized the CatBoost algorithm to forecast day-ahead electricity demand, achieving\\nexceptional accuracy with a minimal 4% root mean square error (RMSE).\\nOYO June 2019 – January 2020\\nBusiness Analyst Banglore, India\\n•Create dashboards, set targets for supply team, drive projects and report business insights to leadership.\\nIndian Register of Shipping May 2018 – July 2018\\nOptimization Algorithm Specialist Intern Mumbai, India\\n•Developed an optimization thrust allocation algorithm using Matlab for Dynamic Positioning of Ships, resulting\\nin a significant increase in fuel efficiency during Onshore operations from 63% to 92%.\\nProjects\\nVinAudit Mar 2022 – May 2022\\nData Science Remote\\n•Developed an end-to-end machine learning model using Python to predict car prices based on various features such as\\nmake, model, year, mileage, and condition. Achieved an accuracy of 98% on the test set and deployed the model to a\\nweb application using Flask for real-time predictions.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"D:\\\\DS\\\\resumes\\\\acads\\\\link.pdf\"\n",
    "\n",
    "from pypdf import PdfReader\n",
    "def read_pdf(file_path):   \n",
    "    output = []\n",
    "    try:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            pdf_reader = PdfReader(f)\n",
    "            count = len(pdf_reader.pages)\n",
    "            for i in range(count):\n",
    "                page = pdf_reader.pages[i]\n",
    "                output.append(page.extract_text())\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file '{file_path}': {str(e)}\")\n",
    "    return str(\" \".join(output))\n",
    "\n",
    "read_pdf(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_position_year(self):\n",
    "    \"\"\"\n",
    "        Extract position and year from a given string.\n",
    "\n",
    "        Args:\n",
    "            text (str): The string from which to extract position and year.\n",
    "\n",
    "        Returns:\n",
    "            list: A list containing the extracted position and year.\n",
    "    \"\"\"\n",
    "    position_year_search_pattern = r\"(\\b\\w+\\b\\s+\\b\\w+\\b),\\s+(\\d{4})\\s*-\\s*(\\d{4}|\\bpresent\\b)\"\n",
    "    position_year = re.findall(\n",
    "        position_year_search_pattern, self.text)\n",
    "    return position_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'read_pdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m text \u001b[39m=\u001b[39m read_pdf(file_path)\n\u001b[0;32m      2\u001b[0m clean_text \u001b[39m=\u001b[39m TextCleaner\u001b[39m.\u001b[39mclean_text(text)\n\u001b[0;32m      3\u001b[0m doc \u001b[39m=\u001b[39m nlp(clean_text)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'read_pdf' is not defined"
     ]
    }
   ],
   "source": [
    "text = read_pdf(file_path)\n",
    "clean_text = TextCleaner.clean_text(text)\n",
    "doc = nlp(clean_text)\n",
    "exp = extract_experience(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Experience \\n OncoSoft Jul 2023   Present \\n Deep Learning Engineering Intern Remote India \\n •Developed an algorithm for resume parsing using the NLP library spaCy \\n •Utilizing strengths of LLM to generate resume scoring system streamlining the process of resume shortlisting \\n LetsTransport Jun 2022   Sep 2023 \\n Business Analyst Banglore India \\n •Championed concept of round tripping & implemented intricate algorithms to enhance roundtripping process \\n resulting in a 2 % margin enhancement 30 % fuel efficiency improvement and 20 % labor productivity increase \\n •Engineered automated pipelines using Python to extract data from heterogeneous portals monitor Google Sheet \\n changes and track revenue This resulted in a 90hour reduction in labor hours per week \\n •Harnessed power of Large Language Models LLMs to summarize unstructured user feedback reducing weekly \\n operational hours by 40 Also engineered an API for fuzzy name matching using LLMs enhancing data accuracy \\n •Strategically reengineered incumbent tables by introducing supplementary columns to facilitate seamless query \\n optimization yielding a remarkable 60 % reduction in query response time for certain cases \\n Cocogenes Feb 2021   Feb 2022 \\n Data Scientist Wayanad India \\n •Parsed data on medicinal & chemical properties geographical distribution of medicinal plants using Spacy \\n •Developed an endtoend computer vision classification project that accurately identifies plant species based on \\n their leaves achieving an impressive 92 % Mean Squared Error MSE for classification \\n Climate Connect Digital Nov 2020   Jan 2021 \\n Data Science Intern Remote \\n •Conducted timeseries forecasting of electricity demand for Delhi DISCOM leveraging statistical analysis of \\n load and weather data Utilized the CatBoost algorithm to forecast dayahead electricity demand achieving \\n exceptional accuracy with a minimal 4 % root mean square error RMSE \\n OYO June 2019   January 2020 \\n Business Analyst Banglore India \\n •Create dashboards set targets for supply team drive projects and report business insights to leadership \\n Indian Register of Shipping May 2018   July 2018 \\n Optimization Algorithm Specialist Intern Mumbai India \\n •Developed an optimization thrust allocation algorithm using Matlab for Dynamic Positioning of Ships resulting \\n in a significant increase in fuel efficiency during Onshore operations from 63 % to 92 % \\n'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "esumes\u0007cadslink.pdf': [Errno 22] Invalid argument: 'D:\\\\DS\\resumes\\x07cadslink.pdf'\n"
     ]
    }
   ],
   "source": [
    "from ResumeProcessor import ResumeProcessor\n",
    "\n",
    "file_path = \"link.pdf\"\n",
    "\n",
    "processor = ResumeProcessor(file_path)\n",
    "data = processor._read_resumes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\DS\\resumes\\x07cadslink.pdf'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.input_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textacy\n",
      "  Using cached textacy-0.13.0-py3-none-any.whl (210 kB)\n",
      "Collecting cachetools>=4.0.0 (from textacy)\n",
      "  Obtaining dependency information for cachetools>=4.0.0 from https://files.pythonhosted.org/packages/a9/c9/c8a7710f2cedcb1db9224fdd4d8307c9e48cbddc46c18b515fefc0f1abbe/cachetools-5.3.1-py3-none-any.whl.metadata\n",
      "  Using cached cachetools-5.3.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: catalogue~=2.0 in c:\\users\\lt\\anaconda3\\envs\\resume\\lib\\site-packages (from textacy) (2.0.9)\n",
      "Collecting cytoolz>=0.10.1 (from textacy)\n",
      "  Obtaining dependency information for cytoolz>=0.10.1 from https://files.pythonhosted.org/packages/b0/5c/13fc01ed00fa4818c9bcbe1e0bdb71af5f972faaf84986a463a93e17479b/cytoolz-0.12.2-cp310-cp310-win_amd64.whl.metadata\n",
      "  Using cached cytoolz-0.12.2-cp310-cp310-win_amd64.whl.metadata (4.7 kB)\n",
      "Collecting floret~=0.10.0 (from textacy)\n",
      "  Obtaining dependency information for floret~=0.10.0 from https://files.pythonhosted.org/packages/08/cf/d11e15aba9d9f08317bd62380045eee588f47bfc6ece6fde62502cd28b2d/floret-0.10.4-cp310-cp310-win_amd64.whl.metadata\n",
      "  Using cached floret-0.10.4-cp310-cp310-win_amd64.whl.metadata (3.2 kB)\n",
      "Collecting jellyfish>=0.8.0 (from textacy)\n",
      "  Obtaining dependency information for jellyfish>=0.8.0 from https://files.pythonhosted.org/packages/f1/26/d91ceb4de9210074fc8f9ddfea98e471e48576dff2d0a252ada4315e0f80/jellyfish-1.0.0-cp310-none-win_amd64.whl.metadata\n",
      "  Using cached jellyfish-1.0.0-cp310-none-win_amd64.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: joblib>=0.13.0 in c:\\users\\lt\\anaconda3\\envs\\resume\\lib\\site-packages (from textacy) (1.3.2)\n",
      "Requirement already satisfied: networkx>=2.7 in c:\\users\\lt\\anaconda3\\envs\\resume\\lib\\site-packages (from textacy) (3.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\lt\\anaconda3\\envs\\resume\\lib\\site-packages (from textacy) (1.22.3)\n",
      "Collecting pyphen>=0.10.0 (from textacy)\n",
      "  Using cached pyphen-0.14.0-py3-none-any.whl (2.0 MB)\n",
      "Requirement already satisfied: requests>=2.10.0 in c:\\users\\lt\\anaconda3\\envs\\resume\\lib\\site-packages (from textacy) (2.31.0)\n",
      "Collecting scipy>=1.8.0 (from textacy)\n",
      "  Obtaining dependency information for scipy>=1.8.0 from https://files.pythonhosted.org/packages/70/03/485f73046134400ea25d3cb178c5e6728f9b165f79d09638ecb44ee0e9b1/scipy-1.11.2-cp310-cp310-win_amd64.whl.metadata\n",
      "  Using cached scipy-1.11.2-cp310-cp310-win_amd64.whl.metadata (59 kB)\n",
      "Collecting scikit-learn>=1.0 (from textacy)\n",
      "  Obtaining dependency information for scikit-learn>=1.0 from https://files.pythonhosted.org/packages/96/cf/a714a655266229b51eb2bda117f15275f12457887f165f3c1cc58ab502f1/scikit_learn-1.3.0-cp310-cp310-win_amd64.whl.metadata\n",
      "  Using cached scikit_learn-1.3.0-cp310-cp310-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: spacy~=3.0 in c:\\users\\lt\\anaconda3\\envs\\resume\\lib\\site-packages (from textacy) (3.5.3)\n",
      "Requirement already satisfied: tqdm>=4.19.6 in c:\\users\\lt\\anaconda3\\envs\\resume\\lib\\site-packages (from textacy) (4.66.1)\n",
      "Requirement already satisfied: toolz>=0.8.0 in c:\\users\\lt\\anaconda3\\envs\\resume\\lib\\site-packages (from cytoolz>=0.10.1->textacy) (0.12.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lt\\anaconda3\\envs\\resume\\lib\\site-packages (from requests>=2.10.0->textacy) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lt\\anaconda3\\envs\\resume\\lib\\site-packages (from requests>=2.10.0->textacy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lt\\anaconda3\\envs\\resume\\lib\\site-packages (from requests>=2.10.0->textacy) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lt\\anaconda3\\envs\\resume\\lib\\site-packages (from requests>=2.10.0->textacy) (2023.7.22)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\lt\\anaconda3\\envs\\resume\\lib\\site-packages (from scikit-learn>=1.0->textacy) (3.2.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\lt\\anaconda3\\envs\\resume\\lib\\site-packages (from spacy~=3.0->textacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\lt\\anaconda3\\envs\\resume\\lib\\site-packages (from spacy~=3.0->textacy) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\lt\\anaconda3\\envs\\resume\\lib\\site-packages (from spacy~=3.0->textacy) (1.0.7)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\lt\\anaconda3\\envs\\resume\\lib\\site-packages (from spacy~=3.0->textacy) (2.0.6)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\lt\\anaconda3\\envs\\resume\\lib\\site-packages (from spacy~=3.0->textacy) (3.0.6)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\lt\\anaconda3\\envs\\resume\\lib\\site-packages (from spacy~=3.0->textacy) (8.1.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\lt\\anaconda3\\envs\\resume\\lib\\site-packages (from spacy~=3.0->textacy) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\lt\\anaconda3\\envs\\resume\\lib\\site-packages (from spacy~=3.0->textacy) (2.4.6)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\lt\\anaconda3\\envs\\resume\\lib\\site-packages (from spacy~=3.0->textacy) (0.7.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\lt\\anaconda3\\envs\\resume\\lib\\site-packages (from spacy~=3.0->textacy) (0.10.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\lt\\anaconda3\\envs\\resume\\lib\\site-packages (from spacy~=3.0->textacy) (5.2.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\lt\\anaconda3\\envs\\resume\\lib\\site-packages (from spacy~=3.0->textacy) (1.10.8)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lt\\anaconda3\\envs\\resume\\lib\\site-packages (from spacy~=3.0->textacy) (2.11.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lt\\anaconda3\\envs\\resume\\lib\\site-packages (from spacy~=3.0->textacy) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lt\\anaconda3\\envs\\resume\\lib\\site-packages (from spacy~=3.0->textacy) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\lt\\anaconda3\\envs\\resume\\lib\\site-packages (from spacy~=3.0->textacy) (3.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\lt\\anaconda3\\envs\\resume\\lib\\site-packages (from tqdm>=4.19.6->textacy) (0.4.6)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\lt\\anaconda3\\envs\\resume\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy~=3.0->textacy) (4.7.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\lt\\anaconda3\\envs\\resume\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy~=3.0->textacy) (0.7.10)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\lt\\anaconda3\\envs\\resume\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy~=3.0->textacy) (0.1.1)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\lt\\anaconda3\\envs\\resume\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy~=3.0->textacy) (8.1.7)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\lt\\anaconda3\\envs\\resume\\lib\\site-packages (from jinja2->spacy~=3.0->textacy) (1.1.1)\n",
      "Using cached cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
      "Using cached cytoolz-0.12.2-cp310-cp310-win_amd64.whl (362 kB)\n",
      "Using cached floret-0.10.4-cp310-cp310-win_amd64.whl (242 kB)\n",
      "Using cached jellyfish-1.0.0-cp310-none-win_amd64.whl (206 kB)\n",
      "Using cached scikit_learn-1.3.0-cp310-cp310-win_amd64.whl (9.2 MB)\n",
      "Using cached scipy-1.11.2-cp310-cp310-win_amd64.whl (44.0 MB)\n",
      "Installing collected packages: scipy, pyphen, jellyfish, floret, cytoolz, cachetools, scikit-learn, textacy\n",
      "Successfully installed cachetools-5.3.1 cytoolz-0.12.2 floret-0.10.4 jellyfish-1.0.0 pyphen-0.14.0 scikit-learn-1.3.0 scipy-1.11.2 textacy-0.13.0\n"
     ]
    }
   ],
   "source": [
    "!pip install textacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LT\\anaconda3\\envs\\resume\\lib\\site-packages\\spacy\\util.py:887: UserWarning: [W095] Model 'en_core_web_sm' (3.6.0) was trained with spaCy v3.6 and may not be 100% compatible with the current version (3.5.3). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "ename": "ConfigValidationError",
     "evalue": "\n\nConfig validation error\ntagger -> label_smoothing\textra fields not permitted\n{'nlp': <spacy.lang.en.English object at 0x00000254F753D5D0>, 'name': 'tagger', 'label_smoothing': 0.0, 'model': {'@architectures': 'spacy.Tagger.v2', 'nO': None, 'normalize': False, 'tok2vec': {'@architectures': 'spacy.Tok2VecListener.v1', 'width': 96, 'upstream': 'tok2vec'}}, 'neg_prefix': '!', 'overwrite': False, 'scorer': {'@scorers': 'spacy.tagger_scorer.v1'}, '@factories': 'tagger'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConfigValidationError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mspacy\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m spacy\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39men_core_web_sm\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\LT\\anaconda3\\envs\\resume\\lib\\site-packages\\spacy\\__init__.py:54\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\n\u001b[0;32m     31\u001b[0m     name: Union[\u001b[39mstr\u001b[39m, Path],\n\u001b[0;32m     32\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m     config: Union[Dict[\u001b[39mstr\u001b[39m, Any], Config] \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39mSimpleFrozenDict(),\n\u001b[0;32m     38\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Language:\n\u001b[0;32m     39\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \u001b[39m    name (str): Package name or model path.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m     \u001b[39mreturn\u001b[39;00m util\u001b[39m.\u001b[39;49mload_model(\n\u001b[0;32m     55\u001b[0m         name,\n\u001b[0;32m     56\u001b[0m         vocab\u001b[39m=\u001b[39;49mvocab,\n\u001b[0;32m     57\u001b[0m         disable\u001b[39m=\u001b[39;49mdisable,\n\u001b[0;32m     58\u001b[0m         enable\u001b[39m=\u001b[39;49menable,\n\u001b[0;32m     59\u001b[0m         exclude\u001b[39m=\u001b[39;49mexclude,\n\u001b[0;32m     60\u001b[0m         config\u001b[39m=\u001b[39;49mconfig,\n\u001b[0;32m     61\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\LT\\anaconda3\\envs\\resume\\lib\\site-packages\\spacy\\util.py:442\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[39mreturn\u001b[39;00m get_lang_class(name\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39mblank:\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m))()\n\u001b[0;32m    441\u001b[0m \u001b[39mif\u001b[39;00m is_package(name):  \u001b[39m# installed as package\u001b[39;00m\n\u001b[1;32m--> 442\u001b[0m     \u001b[39mreturn\u001b[39;00m load_model_from_package(name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    443\u001b[0m \u001b[39mif\u001b[39;00m Path(name)\u001b[39m.\u001b[39mexists():  \u001b[39m# path to model data directory\u001b[39;00m\n\u001b[0;32m    444\u001b[0m     \u001b[39mreturn\u001b[39;00m load_model_from_path(Path(name), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LT\\anaconda3\\envs\\resume\\lib\\site-packages\\spacy\\util.py:478\u001b[0m, in \u001b[0;36mload_model_from_package\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Load a model from an installed package.\u001b[39;00m\n\u001b[0;32m    462\u001b[0m \n\u001b[0;32m    463\u001b[0m \u001b[39mname (str): The package name.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    475\u001b[0m \u001b[39mRETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m    476\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39mimport_module(name)\n\u001b[1;32m--> 478\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mload(vocab\u001b[39m=\u001b[39;49mvocab, disable\u001b[39m=\u001b[39;49mdisable, enable\u001b[39m=\u001b[39;49menable, exclude\u001b[39m=\u001b[39;49mexclude, config\u001b[39m=\u001b[39;49mconfig)\n",
      "File \u001b[1;32mc:\\Users\\LT\\anaconda3\\envs\\resume\\lib\\site-packages\\en_core_web_sm\\__init__.py:10\u001b[0m, in \u001b[0;36mload\u001b[1;34m(**overrides)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39moverrides):\n\u001b[1;32m---> 10\u001b[0m     \u001b[39mreturn\u001b[39;00m load_model_from_init_py(\u001b[39m__file__\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moverrides)\n",
      "File \u001b[1;32mc:\\Users\\LT\\anaconda3\\envs\\resume\\lib\\site-packages\\spacy\\util.py:659\u001b[0m, in \u001b[0;36mload_model_from_init_py\u001b[1;34m(init_file, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m model_path\u001b[39m.\u001b[39mexists():\n\u001b[0;32m    658\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE052\u001b[39m.\u001b[39mformat(path\u001b[39m=\u001b[39mdata_path))\n\u001b[1;32m--> 659\u001b[0m \u001b[39mreturn\u001b[39;00m load_model_from_path(\n\u001b[0;32m    660\u001b[0m     data_path,\n\u001b[0;32m    661\u001b[0m     vocab\u001b[39m=\u001b[39;49mvocab,\n\u001b[0;32m    662\u001b[0m     meta\u001b[39m=\u001b[39;49mmeta,\n\u001b[0;32m    663\u001b[0m     disable\u001b[39m=\u001b[39;49mdisable,\n\u001b[0;32m    664\u001b[0m     enable\u001b[39m=\u001b[39;49menable,\n\u001b[0;32m    665\u001b[0m     exclude\u001b[39m=\u001b[39;49mexclude,\n\u001b[0;32m    666\u001b[0m     config\u001b[39m=\u001b[39;49mconfig,\n\u001b[0;32m    667\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\LT\\anaconda3\\envs\\resume\\lib\\site-packages\\spacy\\util.py:516\u001b[0m, in \u001b[0;36mload_model_from_path\u001b[1;34m(model_path, meta, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    514\u001b[0m overrides \u001b[39m=\u001b[39m dict_to_dot(config)\n\u001b[0;32m    515\u001b[0m config \u001b[39m=\u001b[39m load_config(config_path, overrides\u001b[39m=\u001b[39moverrides)\n\u001b[1;32m--> 516\u001b[0m nlp \u001b[39m=\u001b[39m load_model_from_config(\n\u001b[0;32m    517\u001b[0m     config,\n\u001b[0;32m    518\u001b[0m     vocab\u001b[39m=\u001b[39;49mvocab,\n\u001b[0;32m    519\u001b[0m     disable\u001b[39m=\u001b[39;49mdisable,\n\u001b[0;32m    520\u001b[0m     enable\u001b[39m=\u001b[39;49menable,\n\u001b[0;32m    521\u001b[0m     exclude\u001b[39m=\u001b[39;49mexclude,\n\u001b[0;32m    522\u001b[0m     meta\u001b[39m=\u001b[39;49mmeta,\n\u001b[0;32m    523\u001b[0m )\n\u001b[0;32m    524\u001b[0m \u001b[39mreturn\u001b[39;00m nlp\u001b[39m.\u001b[39mfrom_disk(model_path, exclude\u001b[39m=\u001b[39mexclude, overrides\u001b[39m=\u001b[39moverrides)\n",
      "File \u001b[1;32mc:\\Users\\LT\\anaconda3\\envs\\resume\\lib\\site-packages\\spacy\\util.py:564\u001b[0m, in \u001b[0;36mload_model_from_config\u001b[1;34m(config, meta, vocab, disable, enable, exclude, auto_fill, validate)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[39m# This will automatically handle all codes registered via the languages\u001b[39;00m\n\u001b[0;32m    562\u001b[0m \u001b[39m# registry, including custom subclasses provided via entry points\u001b[39;00m\n\u001b[0;32m    563\u001b[0m lang_cls \u001b[39m=\u001b[39m get_lang_class(nlp_config[\u001b[39m\"\u001b[39m\u001b[39mlang\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m--> 564\u001b[0m nlp \u001b[39m=\u001b[39m lang_cls\u001b[39m.\u001b[39;49mfrom_config(\n\u001b[0;32m    565\u001b[0m     config,\n\u001b[0;32m    566\u001b[0m     vocab\u001b[39m=\u001b[39;49mvocab,\n\u001b[0;32m    567\u001b[0m     disable\u001b[39m=\u001b[39;49mdisable,\n\u001b[0;32m    568\u001b[0m     enable\u001b[39m=\u001b[39;49menable,\n\u001b[0;32m    569\u001b[0m     exclude\u001b[39m=\u001b[39;49mexclude,\n\u001b[0;32m    570\u001b[0m     auto_fill\u001b[39m=\u001b[39;49mauto_fill,\n\u001b[0;32m    571\u001b[0m     validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[0;32m    572\u001b[0m     meta\u001b[39m=\u001b[39;49mmeta,\n\u001b[0;32m    573\u001b[0m )\n\u001b[0;32m    574\u001b[0m \u001b[39mreturn\u001b[39;00m nlp\n",
      "File \u001b[1;32mc:\\Users\\LT\\anaconda3\\envs\\resume\\lib\\site-packages\\spacy\\language.py:1803\u001b[0m, in \u001b[0;36mLanguage.from_config\u001b[1;34m(cls, config, vocab, disable, enable, exclude, meta, auto_fill, validate)\u001b[0m\n\u001b[0;32m   1800\u001b[0m     factory \u001b[39m=\u001b[39m pipe_cfg\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mfactory\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1801\u001b[0m     \u001b[39m# The pipe name (key in the config) here is the unique name\u001b[39;00m\n\u001b[0;32m   1802\u001b[0m     \u001b[39m# of the component, not necessarily the factory\u001b[39;00m\n\u001b[1;32m-> 1803\u001b[0m     nlp\u001b[39m.\u001b[39;49madd_pipe(\n\u001b[0;32m   1804\u001b[0m         factory,\n\u001b[0;32m   1805\u001b[0m         name\u001b[39m=\u001b[39;49mpipe_name,\n\u001b[0;32m   1806\u001b[0m         config\u001b[39m=\u001b[39;49mpipe_cfg,\n\u001b[0;32m   1807\u001b[0m         validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[0;32m   1808\u001b[0m         raw_config\u001b[39m=\u001b[39;49mraw_config,\n\u001b[0;32m   1809\u001b[0m     )\n\u001b[0;32m   1810\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1811\u001b[0m     \u001b[39m# We need the sourced components to reference the same\u001b[39;00m\n\u001b[0;32m   1812\u001b[0m     \u001b[39m# vocab without modifying the current vocab state **AND**\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1817\u001b[0m     \u001b[39m# during deserialization, so they do not need any\u001b[39;00m\n\u001b[0;32m   1818\u001b[0m     \u001b[39m# additional handling.\u001b[39;00m\n\u001b[0;32m   1819\u001b[0m     \u001b[39mif\u001b[39;00m vocab_b \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\LT\\anaconda3\\envs\\resume\\lib\\site-packages\\spacy\\language.py:786\u001b[0m, in \u001b[0;36mLanguage.add_pipe\u001b[1;34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001b[0m\n\u001b[0;32m    782\u001b[0m     pipe_component, factory_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_pipe_from_source(\n\u001b[0;32m    783\u001b[0m         factory_name, source, name\u001b[39m=\u001b[39mname\n\u001b[0;32m    784\u001b[0m     )\n\u001b[0;32m    785\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 786\u001b[0m     pipe_component \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreate_pipe(\n\u001b[0;32m    787\u001b[0m         factory_name,\n\u001b[0;32m    788\u001b[0m         name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m    789\u001b[0m         config\u001b[39m=\u001b[39;49mconfig,\n\u001b[0;32m    790\u001b[0m         raw_config\u001b[39m=\u001b[39;49mraw_config,\n\u001b[0;32m    791\u001b[0m         validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[0;32m    792\u001b[0m     )\n\u001b[0;32m    793\u001b[0m pipe_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_pipe_index(before, after, first, last)\n\u001b[0;32m    794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pipe_meta[name] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_factory_meta(factory_name)\n",
      "File \u001b[1;32mc:\\Users\\LT\\anaconda3\\envs\\resume\\lib\\site-packages\\spacy\\language.py:679\u001b[0m, in \u001b[0;36mLanguage.create_pipe\u001b[1;34m(self, factory_name, name, config, raw_config, validate)\u001b[0m\n\u001b[0;32m    676\u001b[0m cfg \u001b[39m=\u001b[39m {factory_name: config}\n\u001b[0;32m    677\u001b[0m \u001b[39m# We're calling the internal _fill here to avoid constructing the\u001b[39;00m\n\u001b[0;32m    678\u001b[0m \u001b[39m# registered functions twice\u001b[39;00m\n\u001b[1;32m--> 679\u001b[0m resolved \u001b[39m=\u001b[39m registry\u001b[39m.\u001b[39;49mresolve(cfg, validate\u001b[39m=\u001b[39;49mvalidate)\n\u001b[0;32m    680\u001b[0m filled \u001b[39m=\u001b[39m registry\u001b[39m.\u001b[39mfill({\u001b[39m\"\u001b[39m\u001b[39mcfg\u001b[39m\u001b[39m\"\u001b[39m: cfg[factory_name]}, validate\u001b[39m=\u001b[39mvalidate)[\u001b[39m\"\u001b[39m\u001b[39mcfg\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    681\u001b[0m filled \u001b[39m=\u001b[39m Config(filled)\n",
      "File \u001b[1;32mc:\\Users\\LT\\anaconda3\\envs\\resume\\lib\\site-packages\\confection\\__init__.py:756\u001b[0m, in \u001b[0;36mregistry.resolve\u001b[1;34m(cls, config, schema, overrides, validate)\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    748\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mresolve\u001b[39m(\n\u001b[0;32m    749\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    754\u001b[0m     validate: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    755\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, Any]:\n\u001b[1;32m--> 756\u001b[0m     resolved, _ \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_make(\n\u001b[0;32m    757\u001b[0m         config, schema\u001b[39m=\u001b[39;49mschema, overrides\u001b[39m=\u001b[39;49moverrides, validate\u001b[39m=\u001b[39;49mvalidate, resolve\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m    758\u001b[0m     )\n\u001b[0;32m    759\u001b[0m     \u001b[39mreturn\u001b[39;00m resolved\n",
      "File \u001b[1;32mc:\\Users\\LT\\anaconda3\\envs\\resume\\lib\\site-packages\\confection\\__init__.py:805\u001b[0m, in \u001b[0;36mregistry._make\u001b[1;34m(cls, config, schema, overrides, resolve, validate)\u001b[0m\n\u001b[0;32m    803\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_interpolated:\n\u001b[0;32m    804\u001b[0m     config \u001b[39m=\u001b[39m Config(orig_config)\u001b[39m.\u001b[39minterpolate()\n\u001b[1;32m--> 805\u001b[0m filled, _, resolved \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_fill(\n\u001b[0;32m    806\u001b[0m     config, schema, validate\u001b[39m=\u001b[39;49mvalidate, overrides\u001b[39m=\u001b[39;49moverrides, resolve\u001b[39m=\u001b[39;49mresolve\n\u001b[0;32m    807\u001b[0m )\n\u001b[0;32m    808\u001b[0m filled \u001b[39m=\u001b[39m Config(filled, section_order\u001b[39m=\u001b[39msection_order)\n\u001b[0;32m    809\u001b[0m \u001b[39m# Check that overrides didn't include invalid properties not in config\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LT\\anaconda3\\envs\\resume\\lib\\site-packages\\confection\\__init__.py:860\u001b[0m, in \u001b[0;36mregistry._fill\u001b[1;34m(cls, config, schema, validate, resolve, parent, overrides)\u001b[0m\n\u001b[0;32m    858\u001b[0m     schema\u001b[39m.\u001b[39m__fields__[key] \u001b[39m=\u001b[39m copy_model_field(field, Any)\n\u001b[0;32m    859\u001b[0m promise_schema \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mmake_promise_schema(value, resolve\u001b[39m=\u001b[39mresolve)\n\u001b[1;32m--> 860\u001b[0m filled[key], validation[v_key], final[key] \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_fill(\n\u001b[0;32m    861\u001b[0m     value,\n\u001b[0;32m    862\u001b[0m     promise_schema,\n\u001b[0;32m    863\u001b[0m     validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[0;32m    864\u001b[0m     resolve\u001b[39m=\u001b[39;49mresolve,\n\u001b[0;32m    865\u001b[0m     parent\u001b[39m=\u001b[39;49mkey_parent,\n\u001b[0;32m    866\u001b[0m     overrides\u001b[39m=\u001b[39;49moverrides,\n\u001b[0;32m    867\u001b[0m )\n\u001b[0;32m    868\u001b[0m reg_name, func_name \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mget_constructor(final[key])\n\u001b[0;32m    869\u001b[0m args, kwargs \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mparse_args(final[key])\n",
      "File \u001b[1;32mc:\\Users\\LT\\anaconda3\\envs\\resume\\lib\\site-packages\\confection\\__init__.py:926\u001b[0m, in \u001b[0;36mregistry._fill\u001b[1;34m(cls, config, schema, validate, resolve, parent, overrides)\u001b[0m\n\u001b[0;32m    924\u001b[0m         result \u001b[39m=\u001b[39m schema\u001b[39m.\u001b[39mparse_obj(validation)\n\u001b[0;32m    925\u001b[0m     \u001b[39mexcept\u001b[39;00m ValidationError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 926\u001b[0m         \u001b[39mraise\u001b[39;00m ConfigValidationError(\n\u001b[0;32m    927\u001b[0m             config\u001b[39m=\u001b[39mconfig, errors\u001b[39m=\u001b[39me\u001b[39m.\u001b[39merrors(), parent\u001b[39m=\u001b[39mparent\n\u001b[0;32m    928\u001b[0m         ) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    929\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    930\u001b[0m     \u001b[39m# Same as parse_obj, but without validation\u001b[39;00m\n\u001b[0;32m    931\u001b[0m     result \u001b[39m=\u001b[39m schema\u001b[39m.\u001b[39mconstruct(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mvalidation)\n",
      "\u001b[1;31mConfigValidationError\u001b[0m: \n\nConfig validation error\ntagger -> label_smoothing\textra fields not permitted\n{'nlp': <spacy.lang.en.English object at 0x00000254F753D5D0>, 'name': 'tagger', 'label_smoothing': 0.0, 'model': {'@architectures': 'spacy.Tagger.v2', 'nO': None, 'normalize': False, 'tok2vec': {'@architectures': 'spacy.Tok2VecListener.v1', 'width': 96, 'upstream': 'tok2vec'}}, 'neg_prefix': '!', 'overwrite': False, 'scorer': {'@scorers': 'spacy.tagger_scorer.v1'}, '@factories': 'tagger'}"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "spacy.load('en_core_web_sm')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resume",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
